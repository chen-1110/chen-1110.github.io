---
layout: post
categories: 技术文章
author: chen
title: K8S学习记录
---
## 1.简介

- 是什么

自动化管理容器的平台

- 能做什么

自动部署

资源调度

服务发现和负载均衡

存储挂载

自我修复

密钥管理

## 2. 架构

k8s是一个集群，由一个主节点（control plane控制节点）和多个工作节点（node）组成

![image-20250604214939902](https://raw.githubusercontent.com/chen-1110/image/main/image-20250604214939902.png)

### 2.1 控制平面组件（control plane components）

全局控制器，负责资源调度，检测，请求响应等

#### 2.1.1kube-apiserver

负责处理k8s集群的api请求

> API server是 Kubernetes 控制平⾯的组件， 该组件负责公开
> API，负责处理接受请求的⼯作 。 API server 是 Kubernetes
> Kubernetes API 服务器的主要实现是 kube-apiserver。
> 设计上考虑了⽔平扩缩，也就是说，它可通过部署多个实例来进⾏扩
> kube-apiserver 的多个实例，并在这些实例之间平衡流量

#### 2.1.2 etcd

存储作用，集群数据库，键值数据存储

#### 2.1.3 kube-scheduler

资源调度 ❓❓

> kube-scheduler 是控制平⾯的组件， 负责监视新创建的、未指定运⾏节点 node
> 的 Pods， 并选择节点来让 Pod 在上⾯运⾏。调度决策考虑的因素包括单个 Pod 及
> Pods 集合的资源需求、软硬件及策略约束、 亲和性及反亲和性规范、数据位置、⼯作
> 负载间的⼲扰及最后时限。

#### 2.1.4 kube-controller-manager

由多个控制器组成，包括，

节点（node）控制器，负责在节点出现故障进行通知和响应；

任务处理器，监测一次性任务，并创建pods来执行一次性任务；

端点分片控制器，填充endpointSlice对象，以提供service和pod的链接； ❓❓

服务账号控制器，为新的命名空间创建默认的服务账号❓

#### 2.1.5 cloud-controller-manager(optional)

接入各云服务平台

### 2.2 node组件

执行器，用来运行工作容器

#### 2.2.1 kubelet

确保pod健康？？❓❓

> kubelet 会在集群中每个节点（node）上运⾏。 它保证容器（containers）都运⾏
> 在 Pods 中。
> kubelet 接收⼀组通过各类机制提供给它的 PodSpecs， 确保这些 PodSpecs 中描
> 述的容器处于运⾏状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容
> 器。

#### 2.2.2 kube-proxy

网络代理，实现kubernetes service相关概念

> kube-proxy是集群中每个节点（node）上所运⾏的⽹络代理， 实现 Kubernetes
> 服务（Service）概念的⼀部分。
> kube-proxy 维护节点上的⼀些⽹络规则， 这些⽹络规则会允许从集群内部或外部的
> ⽹络会话与 Pod 进⾏⽹络通信。
> 如果操作系统提供了可⽤的数据包过滤层，则 kube-proxy 会通过它来实现⽹络规
> 则。 否则， kube-proxy 仅做流量转发。

#### 2.2.3 容器运行时

负责提供容器运行环境，如docker，containerd等实现

> 容器运⾏环境是负责运⾏容器的软件。
> Kubernetes ⽀持许多容器运⾏环境，例如 containerd、 CRI-0、 Docker 以及
> Kubernetes CRI 的其他任何实现。

### 2.3 插件

dns

web仪表盘

资源监控

日志

![image-20250604221410711](https://raw.githubusercontent.com/chen-1110/image/main/image-20250604221410711.png)



### 2.4 集群安装（略）

## 3. pod & container

### 3.1 pod简介

pod是kubernetes中创建，管理，部署的最小计算单元，pod是管理一组容器的集合，这些容器共享网络，存储，上下文，类似docker-compose

pod中的多个容器被安装到同一物理机上，一起调度

pod有两种使用方式，一是一个pod只运行单个容器，通过副本（replication）实例进行横向扩展，副本运行在其他pod上。 二是将多个高度管理，协同工作的容器运行在一个pod上，共享网络和存储协同工作

### 3.2 pod基本操作

查看： kubectl get pods -A

创建：kubectl apply -f nginx-pod.yml  执行yml文件创建

yml文件示例：

```
# nginx-pod.yml
apiVersion: v1
kind: Pod
metadata:
name: nginx
spec:
containers:
- name: nginx
image: nginx:1.19
ports:
- containerPort: 80
```

删除： kubectl delete podxxx

​			kubectl delete -f pod.yml

进入容器： kubectl exec -it nginx -- bash

查看日志： kubectl logs -f podxxx

查看pod详情： kubectl describe pod podxxx

pod标签指令：

```
apiVersion: v1
kind: Pod
metadata:
name: myapp
labels:
name: myapp #创建时添加
spec:
containers:
- name: nginx
image: nginx:1.21
imagePullPolicy: IfNotPresent
- name: redis
image: redis:5.0.10
imagePullPolicy: IfNotPresent
restartPolicy: Always
# 查看标签
$ kubectl get pods !'show-labels
# kubectl label pod pod名称 标签键值对
$ kubectl label pod myapp env=prod
# 覆盖标签 !'overwrite
$ kubectl label !'overwrite pod myapp env=test
# 删除标签 -号代表删除标签
$ kubectl label pod myapp env-
# 根据标签筛选 env=test/env > = <
$ kubectl get po -l env=test
$ kubectl get po -l env
$ kubectl get po -l '!env' # 不包含的 pod

$ kubectl get po -l 'env in (test,prod)' #选择含有指定值的 pod
$ kubectl get po -l 'env notin (test,prod)' #选择含有指定值的 pod
```

### 3.3 pod生命周期

Pod 遵循预定义的⽣命周期，起始于 Pending 阶段， 如果⾄少其中有⼀个主要容器正常启动，则进⼊ Running ，之后取决于 Pod 中是否有容器以失败状态结束⽽进⼊Succeeded 或者 Failed 阶段。与此同时Pod 在其⽣命周期中只会被调度⼀次。 ⼀旦 Pod 被调度（分派）到某个节点， Pod 会⼀直在该节点运⾏，直到 Pod 停⽌或者被终⽌。

### 3.4 container

#### 3.4.1 容器生命周期

- 一旦调度器将pod分派到某个节点，kubelet就开始为pod创建容器，容器状态共由waiting，running，terminated三种，

- 容器会在被创建时同步执行poststart回调，在容器终止前执行prestop回调

示例代码：

```
# nginx-pod.yml
apiVersion: v1
kind: Pod
metadata:
name: nginx
spec:
containers:
- name: nginx
image: nginx:1.19
lifecycle:
postStart: #容器创建过程中执⾏
exec:
command: ["/bin/sh","-c","echo postStart !$
/start.txt"]
preStop: #容器终⽌之前执⾏
exec:
command: ["/bin/sh","-c","echo postStop !$ /stop.txt
!& sleep 5"]
ports:
- containerPort: 80
```

- 容器重启策略： yml文件中restartpPolicy键值对，value有三种，always, onfailure, never

- 自定义容器启动命令：

示例代码：

```
apiVersion: v1
kind: Pod
metadata:
name: redis
labels:
app: redis
spec:
containers:
- name: redis
image: redis:5.0.10
command: ["redis-server"] #⽤来指定启动命令
args: ["!'appendonly yes"] # ⽤来为启动命令传递参数
#args: ["redis-server","!'appendonly yes"] # 单独使⽤修改启动命
令并传递参数
#args: # 另⼀种语法格式
# - redis-server
# - "!'appendonly yes"
imagePullPolicy: IfNotPresent
```

#### 3.4.2 容器探针

kubelet对容器进行定期健康诊断，确保容器有效运行，有多种方式，如执行命令，发网络请求

探针有三种类型，分别是，

livenessProbe，监控容器是否正在运行，如果探针执行失败，会杀死容器，并根据重启策略进行后续操作

readinessProbe，监控容器是否能正常提供请求服务，如果失败，会删除该pod的IP地址

startupProbe，比较特殊，引用原文不展开解释。

> startupProbe 1.7+  指示容器中的应⽤是否已经启动。如果提供了启动探针，则所
> 有其他探针都会被 禁⽤，直到此探针成功为⽌。如果启动探测失败， kubelet 将杀
> 死容器， ⽽容器依其重启策略进⾏重启。 如果容器没有提供启动探测，则默认状态为
> Success

探针方式： exec命令，grpc，httpGet网络请求，tcpSocket连接

示例代码：

```yaml
# probe-liveness-httget.yml
apiVersion: v1
kind: Pod
metadata:
name: liveness-httpget
labels:
httpget: httpget
spec:
containers:
- name: nginx
image: nginx:1.19
ports:
- containerPort: 80
args:
- /bin/sh
- -c
- sleep 7;nginx -g "daemon off;" #这⼀步会和初始化同时开始运⾏，也
就是在初始化5s后和7秒之间，会检测出⼀次失败， 7秒后启动后检测正常，所以pod不会
重启
imagePullPolicy: IfNotPresent
livenessProbe:
httpGet: #httpget
port: 80 #访问的端⼝
path: /index.html #访问的路径
initialDelaySeconds: 5 #初始化时间5s
periodSeconds: 4 #检测间隔时间4s
timeoutSeconds: 1 #默认检测超时时间为1s
failureThreshold: 3 #默认失败次数为3次，达到3次后重启pod
successThreshold: 1 #默认成功次数为1次， 1 次代表成功
```

#### 3.4.3 资源限制

对于容器可以配置内存和cpu的限制，限制分为request和limit两种，request为基础资源数，limit为最大资源数，cpu使用数最大为limit，内存超出limit会oom

示例代码：

```
# nginx-memory-demo.yaml
apiVersion: v1
kind: Pod
metadata:
name: nginx-memory-demo
spec:
containers:
- name: nginx-memory-demo
image: nginx:1.19
resources:
requests:
memory: "100Mi"
limits:
memory: "200Mi"
```

### 3.5 init容器

init容器是一个pod中所有容器中最先创建运行的，若pod存在init容器，其他容器需要等候init容器创建后再创建，若init创建失败，整个pod状态都会失败，可以将一个pod中容器运行的基本需要，如拉去对象等内容放置在init容器中。

### 3.6 节点亲和性分配pod

通过配置节点亲和性，可以让pod运行在资源更合适，系统更稳定的节点上，例如pod需要gpu，通过配置节点亲和性让pod分配到有gpu的机器节点上，再例如为了应用服务高可用，将同一应用副本尽量分散到不同节点上。

这里又分为通过node亲和性分配和pod亲和性分配

node亲和性分配：给节点添加标签，在pod的启动yml中配置对标签的亲和性，优先分配到亲和性更高的标签节点上。这里的亲和性配置又有两种，requiredDuringSchedulingIgnoredDuringExecution为标签必须满足规则，若不满足则不调度，preferredDuringSchedulingIgnoredDuringExecution  为优先调度满足规则标签，若不满足仍会调度。

pod亲和性分配：类似node亲和性，只不过是通过pod的标签进行亲和判定。

示例代码：

```
apiVersion: v1
kind: Pod
metadata:
name: with-node-affinity
spec:
affinity:
nodeAffinity:
#节点最好具有⼀个键名为 app 且取值为 fast 的标签。
preferredDuringSchedulingIgnoredDuringExecution:
- weight: 1 #取值范围是 1 到 100
preference:
matchExpressions:
- key: ssd
operator: In
values:
- fast
- weight: 50
preference:》
matchExpressions:
- key: app   
operator: In
values:
- demo
containers:
- name: nginx
image: nginx:1.19
```

## 4.controller控制器

### 4.1 控制器简介

是什么？

前面已经学到了怎么创建pod，但实际应用k8s一般不会直接创建pod，而是使用控制器，从而提供副本管理，自动伸缩，网络通信等效果。可以认为，pod是炸弹，控制器就是炮筒。

有哪几种控制器？

deployment： 最常用的控制器，提供副本管理的功能，包括扩缩，版本控制，回退等

statefulset：有状态的控制器，保证启动的pod名称编号不变，从而达到存储持久化的用途。也有控制pod启动顺序的功能

daemonset：一个node只有一个，守护控制器，比较特殊用的不多

job：顾名思义，任务型控制器，运行结束达到到达目标状态后就会删除

#### 4.2 deployment示例

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:1.19
          ports:
            - containerPort: 80
```

#### 

## 5. service

#### 5.1 是什么？

k8s内部容器之间互相访问的通道，例如我们使用controller创建了一组多副本的java应用程序pod，又创建了一组数据库应用程序pod，java需要访问数据库时，通过service来访问。service是一组pod的抽象统一。

#### 5.2 有哪几种类型？

nodePort类型：node会暴露端口，通过node暴露的端口来访问

clusterIp类型：创建一个虚拟ip，容器内通过name或者ip来访问，主要使用姿势

loadBalancer类型： 云厂商的类似nodePort，略

ExternalName类型：在k8s增加一个dns映射，从而访问，略

#### 5.3 示例：

##### 创建nginx和mysql pod

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  replicas: 1
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql/mysql-server:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: root
        ports:
        - name: mysql
          containerPort: 3306
---
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  selector:
    app: mysql
  ports:
  - name: mysql
    port: 3306
    targetPort: 3306
	type: ClusterIP
```

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
    spec:
      hostNetwork: true
      containers:
      - name: nginx
        image: nginx:latest
        #command: ["/bin/sh", "-c"]
        #args:
        #- apt-get update && apt-get install -y mysql-client && nginx -g 'daemon off;'
        ports:
        - name: http
          containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    app: nginx
  ports:
  - name: http
    port: 8081
    targetPort: 80
	type: ClusterIP
```

##### 相互访问

```shell
# 进入 nginx 访问mysql
$ mysql -h mysql -uroot -ppassword
# 注意：这里的 mysql 是 MySQL Service 的名称，而不是 Pod 的名称。
```

## 6. 存储卷

### 6.1是什么？

pod在运行时产生的数据，在pod销毁或重启后会自动清理，像数据库数据等需要持久化存储的数据，需要用到卷将pod的本地数据进行持久化存储，卷是持久化存储的抽象概念，其之下有emptyDir，hostPath，nfs等多种实现。

此外pod需要共享读写数据的场景，由于pod各自存储空间隔离，通过卷来共享读写

### 6.2存储类型

emptyDir: 临时数据，较少使用

hostPath：pod和node通过path关联，存在缺陷，node与pod数据强关联，若pod下次启动挂载在其他node则读取不到，较少使用

nfs: 远程文件系统通过path关联，较多使用

pv，pvc：类似nfs，提供运维便利

configMap：存储无需加密的配置信息，如应用配置

secret：存储加密信息，非强加密，通过base64加密

### 6.3示例

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-test
spec:
  containers:
  - name: busybox
    image: busybox
    command: [ "/bin/sh", "-c", "while true; do sleep 3600; done" ]
    volumeMounts:
    - name: nfs-volume
      mountPath: /mnt/nfs
  volumes:
  - name: nfs-volume
    nfs:
      server: <NFS_SERVER_IP>
      path: /path/to/nfs/share
```

## 7. ingress

### 7.1是什么？

为集群外部暴露流量入口，提供http/https服务，通过路径匹配规则负载均衡分发流量到不同service

### 7.2 常见使用

slb -> nginx-ingress -> service

alb -> service

mse -> service

