---
layout: post
categories: 技术文章
author: chen
title: MySQL核心原理(两万字长文解析)
---
## 一、执行流程

![img](https://raw.githubusercontent.com/chen-1110/image/main/13526879-3037b144ed09eb88.png)

1. 连接器：检查数据库连接是否有权限
2. 分析器：语法解析，检查是否存在语法错误（缓存mysql8.0已废除）
3. 优化器：根据库表情况，选择合适的索引优化计划
4. 执行器：调用存储引擎取数据（存储引擎插件型，可针对不同库表使用不同存储引擎，常用innodb）

**引申概念：buffer pool和页数据**

![image-20251201080740238](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201080740238.png)

mysql是一个重io型的中间件，想象亿级的表数据存储在几百G的磁盘上，每次查询将G级别的数据载入内存再做查找显然是不可能的，mysql引入了数据页和数据库缓冲池(buffer pool)的概念，它将G级别的表数据划分成许多16KB的页，每次操作数据时会在内存的buffer pool里查看是否有该记录所在的页记录，找到直接操作页数据，找不到从磁盘载入该页操作。

（ps. 这里会有一个一致性的问题，后面日志模块会讲如何解决，先认为buffer pool和磁盘数据是一致的）

## 二、索引

### 2.1 如何自己设计一个可用的索引结构

mysql作为存储中间件，常会出现单表千万级数据记录，针对如此大数据量的数据查询，修改，mysql是如何做到毫秒级的响应耗时。

插入其实是一个简单的问题，最笨单链表插入只是O(1)的复杂度，难点主要在查询，比如我们做这样的查询操作

```mysql
select * from xx表 where id = 100000;
```

假设这是一张数据量可能达亿级的表，怎么能够做到毫秒级的响应时间呢，有什么好的方案呢？

#### 2.1.1链表存储

首先排除，随着数据量增多，一定无法做到毫秒级响应

#### 2.1.2 二叉搜索树

对id字段做二叉搜索树，每个节点key是id值，value是该行记录的数据，1 亿的 log₂ n 大约是 26.6，是能够满足毫秒级，但是存在树高度差的问题，容易出现高度差极大的bad case，极端情况复杂度退化到O(N)，无法满足目标

![斜树](https://raw.githubusercontent.com/chen-1110/image/main/oblique-tree.png)

#### 2.1.3 平衡二叉搜索树（avl）

树高读差不会超过1，可以做到O(logN)，**“似乎”**可以满足我们的目标

![img](https://raw.githubusercontent.com/chen-1110/image/main/avl-tree.png)

#### 2.1.4 红黑树

avl树的优化版本，avl树由于严格要求树差小于1，需要在插入时做相当多的旋转操作，耗时较多，红黑树只追求大致的平衡，树差不会过大，旋转操作耗时少，整体更适合做二分搜索类功能，**“似乎”**可以满足目标

问题：在avl树和红黑树这里我们都用引号标注了似乎可以满足目标，但是其实这种设计也是不可取的，关键的问题在于，我们每做一次节点的比较都要从磁盘取对应数据，26次就要进行26次磁盘io，按照一次io几ms来看，几百ms凑活能用，但是这并不是最好的设计，有没有什么更好的设计呢。

#### 2.1.5 B树/B+树

##### 2.1.5.1底层设计

红黑树，avl树底层的问题在于，一次io操作，能够进行的信息过滤太少了，拿上面图例子来说，需要三次io，每次io在内存中对比大小，如果我们1次io将整颗树的信息加载到内存，再在内存完成三次比较大小，相较于磁盘io，内存的比较耗时几乎可以忽略，那么相当于将三次io的时间减少到了一次，如果是一颗1000个节点的树，前者要10次io，后者1次io，相当于性能优化了10倍。这就是b树/b+树的底层思想。

##### 2.1.5.2细化算法实现

了解了底层思想，我们再细化下算法实现，这里实现上有两个问题

###### 一次io加载多少节点

加载的节点越多，单次io的性能优化就越大，但是节点并不是越多越好，节点太多，带宽增大会耗时，载入后查找耗时也会增加，更重要的问题是内存buffer pool的命中率会降低(这个先忽略，后面会讲)，经过综合性能考量统计，innodb默认的一次加载大小是16kb，对于mysql行记录16kb可以粗估为1000个节点，innodb将这个16kb的节点定义为数据页，后续我们也会用这个词来讲述。

###### 加载哪些节点

拿下面这个树来说，数据库里有1-15的记录，假设一个数据页有3条记录（只是为了简化的假设，实际约1000），每一次加载的应该是哪三条呢，这个其实有一些数学统计的概念，为了获得更多的信息做筛选，一定是取间隔最远的三条记录效率更高，这样能最大程度做筛选，对应的第一次查应该是【4，8，12】这三个元素，也就是树的头节点，比如我们要查找的是值是x，第一次载入【4，8，12】后，会将x与这个值比较，根据比较结果在1-3，5-7，9-11，13-15四个数据页里取下一次io。

```
              8                                   
        /           \
       4             12
     /   \         /    \
    2     6      10      14
   / \   / \    /  \    /  \
  1   3 5   7  9   11  13  15
```

二者等价

```
                       [ 4 | 8 | 12 ]
                  /        |         |          \
         [ 1 | 2 | 3 ] [ 5 | 6 | 7 ] [ 9 | 10 | 11 ] [ 13 | 14 | 15 ]
```



##### 2.1.5.3实际算法实现

此时我们的算法实现已经离b树非常接近了，但是实际上b树的实现与我们的还有些略微的区别，b树还做了一些优化

###### 2.1.5.3.1 b树的优化

b树的底层数据结构不是树，而是一个正序数组，每次载入内存时通过二分查找，熟悉算法的同学知道平衡二叉搜索树一般都会用排序数组代替，这两者作用是完全一样的，而数组相较树结构减少了指针的存储空间，对于b树来说，减少存储的作用是相当大的，可以存入更多的数据。

###### 2.1.5.3.2 b+树的优化

刚才我们的示意图里只画了比较的id节点值，可以将这个视为key，每一个元素还有其对应的sql完整行记录，可以将其视为value。

b+树相较b树做了两个优化

1.b+树的非叶子节点只存储key值，不存储value值

这个会带来什么影响呢，首先缺点是，之前b树可能在没有查到最后一层就找到了key，由于其也存储了value，便能直接返回，而b+树需要走到底层数据页才能完成查询。这对于性能影响有多大呢，可以粗估一下，16kb=1000条，三层记录树是1000+ 1000* 1000 +1000* 1000 *1000，未走到底层的节点不足1/1000，影响面极小。

那么优点是什么呢，key的存储空间只有id，value的存储是整条记录，可能会产生10倍的空间节省，对于b+树这个优化极大，每个数据页多存10倍元素，同时下层数据页数量增加10倍，会极大的矮化树，更大程度减少io次数

2.b+树的叶子节点元素前后增加指针

这个优化的好处就是进行范围查询时直接沿着指针遍历即可，减少了尾部的数据页查询。

现代数据库系统中，基本都采用b+树作为底层结构

###### 2.1.5.3.3 innodb还做了哪些优化

区分聚簇索引和非聚簇索引

对于主键的索引，称之为聚簇索引，其value是行记录数据

对于非主键的索引，称之为非聚簇索引（二级索引），其value是主键值

这样做的原因是为何呢，对于二级索引，若value是主键值，随着数据增大主键页分裂，其行记录数据地址更新，需要更新涉及到的所有二级索引的value，性能太差，使用主键值随查询会多查一颗二叉树，但性能较为平均可以接受

#### 2.1.6 实际性能

对于聚簇索引来说，非叶子的b+树节点预估存储行记录1000条，叶子树节点由于有占空间的行记录预估可存储100条，那么一个二层b+树，预估可存储行记录1000 + 100 * 1000约为10w条，对于一个三层b+树，预估可存储行记录1000 + 1000 * 1000 + 100 * 1000 * 1000约为1亿条，对于4层b+树可存储1000亿条，对于大部分表来说，聚簇索引的b+树查询需要2-4次io。

### 2.2 其他面试知识点

覆盖索引：若查询数据在索引key内，无需回表

联合索引：多个字段建索引，左前缀匹配

索引下推：将函数运算在查到二级索引后完成，无需回标









## 三、日志系统

### 3.1 redolog

#### 3.1.1 bufferpool一致性的解法

还记着之前一开始我们讲到的数据库缓冲池buffer pool吗，之前有提到buffer pool的更新和磁盘数据的更新数据有一致性问题，该问题如何解决的呢？这就引出了这一节的重点内容redolog。

**按行更新磁盘**

继续刚才的问题，我们先想想buffer pool和磁盘的更新策略有什么呢，redis缓存一致性的解决很多人都熟悉，拿redis经典的旁路缓存模式来说

> redis旁路缓存模式
>
> 读取数据时先读缓存，若有数据直接使用，若缓存为空读取db，并将db数据写入缓存
>
> 修改数据时先改db，改完之后删除缓存

buffer pool是否可以借鉴该思路吗，显然是不行的，或者说如果这么做的话性能很差，比如我们修改了一条行记录，就要对整个数据页16kb（1000行记录）进行磁盘io修改，io1000条但实际有用的只有一条，利用率很低，且这种磁盘io是随机写，需要找到磁盘内该数据页准确位置写入，可能还会发生页分裂等行为，耗时也是可观的。

**按页更新磁盘**

那还有什么思路呢，既然一次改1行写磁盘利用率低，能不能写满1页/0.5页更新磁盘吗，这是一个美好的愿景，但是这样做有天然的缺陷，最关键的，如果还没写满1页的时候数据库宕机了，这些修改就全部丢失了，innodb引擎设计上无法接受这种丢失（实际上其他引擎如myisam是接受崩溃丢失的，这也是其一个巨大缺陷），该方案也不可取。此外这种数据页的更新也是对磁盘某位置随机写，也存在页分裂，耗时也是不小的。

**redolog追加写**

前面的两个方案有巨大缺陷，这就引出了innodb的一个优秀设计redolog

讲redolog之前我们先讲下其设计思想Write-Ahead Log，即在持久化一个数据页之前，先将内存中相应的日志页持久化，这种设计思想的的底层优势在于，先做存储计算后置，这里典型的例子是mysql45讲里孔乙己里酒馆老板的例子

> ![image-20251201115424397](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201115424397.png)

回到mysql数据库里，当我们对一行数据做更新后，先将更新写入日志redolog里，redolog里存储了具体的该数据页的物理修改内容，待系统空闲时再批量将redolog里的日志写入对应具体的数据页。

这样做的优势是什么，有人会问前面按行更新磁盘是1次io，这里写redolog也要进行1次io，不也耗时大吗，实则不然，在单次写入上可能差距不大，仅仅是页的额外的查找计算分裂会有性能差，但是当写入并发稍微高一点时，性能就会有巨大差异，首先redolog是追加写，相较于数据页的每一页写入在不同的位置，并发下一批redolog的写入是顺序写入的，其比数据页不同位置随机写磁盘性能会高很多，磁盘指针几乎在同一位置顺序移动，无需像随机写一样反复移动，这就极大地提高了io的性能。

![image-20251201120702597](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201120702597.png)

#### 3.1.2 redolog的作用

上一节类似于顶层设计，我们已经讲完了redolog的精髓，后面的内容基本是具体的工程实现，这里我们总结一下redolog的作用

通过wal思想，极大地提高写入速度的同时， 保障了数据库崩溃场景下数据能够安全恢复，为事务持久性提供保障

#### 3.1.3 redolog的结构

##### redolog buffer

redolog主要有redolog buffer和redolog file两个重要部分

redolog并不是每条sql都会写入磁盘，redolog会首先写在内存里，然后根据配置的参数策略写入到磁盘redolog file里。**注意这里的刷盘是redolog本身的刷盘，而不是redolog到数据页的刷盘，这两个概念容易混淆，一定要区分开**

##### redolog file

redolog的磁盘数据，其是一个环形的数据段，数据段中有两个指针checkpoint和write pos，初始两个指针位置相同当写入数据时，write pos会后移，当write pos快要再次追上checkpoint时，innodb会暂停所有写入线程，将整个redologfile对应的buffer pool里的数据页更新到磁盘里，checkpoint移到write pos的位置（称之为擦除），从而实现循环利用，另外不一定write pos追到checkpoint会发生擦除，mysql系统定时也会在空闲时擦除数据追赶进度。

![image-20251201124010889](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201124010889.png)

##### redolog buffer和redologfile的具体刷盘策略

具体的来说，其通过innodb_flush_log_at_trx_commit来控制

- 设置为0：表示每次事务提交时不进行刷盘操作（系统默认master thread每隔1s进行一次重做日志的同步），这种情况下在mysql崩溃时可能会丢失1s的已提交事务的数据

![image-20251201122742831](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201122742831.png)

- 设置为1：表示每次事务提交时都将进行同步，刷盘操作，同时也有后台1s定时刷新（默认情况下设置为1，这样能够严格保证提交的事务不会崩溃后丢失）

  **重点**： 这里有一个很多资料都写的模糊的地方，就是在事务提交时，redolog里还会写入一条事务的commit记录，标志该事务提交了，不然崩溃恢复的时候无法得知哪些行记录修改需要恢复，更具体地说，这里要通过undolog的配合，可以先留个印象后面再重点讲。

  ps.一个小问题，没提交的事务会写入redolog file吗？

  当然会且大量如此，后台线程会1s定期刷新，那么崩溃恢复时会不会将没提交的行修改恢复呢，答案是不会，因为上面重点又说，事务提交也会写一条commit记录到redolog，能够根据此判断是否要恢复

  > 另外在学习知识的时候一定要有全局意识，不要陷入细节里，做系统设计，读源码的时候也是如此，一定要掌握抽象思想。
  >
  > 比如这里commit提交要做记录是抽象的，只要有这个记录信息，我们就可以识别恢复内容，而底层的实现是具体的，无论是undolog还是什么xxlog，先不要过分输入后面会讲，一定要学会抓整体再细节，抓抽象再实现，发展眼光看事物。
  >
  > 再比如，这里redolog利用wal记录信息是抽象的，只要记录了该记录的，一定能之后处理，至于记录了啥怎么处理了，是具体的，学习新知识可以先看抽象整体理解后再看具体

![image-20251201122904604](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201122904604.png)

- 设置为2：表示每次事务提交时都只把 redo log buffer 内容写入 page cache，不进行同步。由os自己决定什么时候同步到磁盘文件，同设置1可能会丢1s数据

#### 3.1.4 整体流程总结

![image-20251201125326531](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201125326531.png)

1. 读数据页到内存
2. 内存修改数据页，并写入redolog buffer
3. 事务commit/后台线程定期刷新，将redolog buffer刷入redolog file
4. 定期将一批修改后的数据页刷新到内存，redolog file checkpoint后移擦除



### 3.2 undolog

#### undolog是什么

undolog是innodb为了保障事务一致性而设计的日志。具体来说它记录了每一条行记录操作的逆操作，例如insert时会记录delete的undolog，update会记录update前的undolog。undolog也以数据页的格式存储在undo表空间里，称之为undo页，这也意味着undolog与redolog这样的日志追加写类型的文件不同，其是类似行数据数据页型的随机写数据。

> innodb几大优势：支持事务，行锁，性能好

我们将一些容易混淆的概念写在开头，首先undolog也会产生redolog，这个如何理解呢，从抽象的角度，innodb的存储分为信息本身和信息的日志记录两部分，狭义上的信息是指对一条行数据的增删改，而广义上信息不仅包括行数据的增删改，事务的启动提交，数据页的分裂合并，undolog页的新增记录这都都属于广义上的信息，而redolog的作用是对于信息提供快速持久化能力，事实上刚才提到的这些广义信息都会存储在redolog里

（ps. redolog不区分其类型，redolog是页级别的记录，redolog只做一件事崩溃后将这些页操作恢复，剩下的交给其他模块做）

#### **undolog的作用**

1.回滚数据

包括正常情况下的回滚，事务在未提交前，进行了一些行记录的修改，之后可能会调指令回滚或因报错回滚，这些情况都是依赖undolog实现的，因为undolog记录的是逆操作，将要回滚事务的逆操作执行修改数据页即可

以及崩溃场景下的回滚，事务未提交前，进行了一些行记录的修改，之后mysql发生崩溃重启，此时的崩溃恢复流程是，innodb会根据redolog将崩溃前的操作在内存全部执行，相当于在内存中还原出了崩溃前的现场，之后会根据是否有事务commit的redolog，若没有则执行undolog回滚该事务，若存在commit则不做回滚（这里是不是回答了3.1.3的小问题，回去看看吧~）











2.MVCC(这个会在下一章事务里面讲解，先略过)

#### undolog的结构

这里不直接公布答案，读者可以自己来想想刚才讲undolog作用一节，undolog要实现能做到回滚数据体结构里要包含哪些信息呢

1.sql的逆操作

undolog无需像redolog一样记录数据页的完整变化，只要记一条sql的逆操作就好了，这是为何呢，因为redolog已经帮你把现场还原好了，直接做sql操作就好了

2.事务id

我们需要将未提交的事务回滚，在通过redolog筛选到提交的事务记录后，需要知道undolog属于哪个事务的操作，是否在其中，若不在则回滚

此外刚才讲到undolog的存储是在数据页中，当事务提交且无需再使用该事务的undolog时，会将undolog的指针放到列表中待定期回收，undolog页的回收并不会清理空间，而是直接给下个事务复用

#### undolog使用举例

先补充一个小消息，innodb的行记录，有几个隐藏字段，分别是DB_TRX_ID，该记录最后一次变更的事务id，DB_ROLL_PTR回滚指针，即指向该记录的undolog，用来回滚。

**当我们执行INSERT时：**

```mysql
begin; 
INSERT INTO user (name) VALUES ("tom");
```

插入的数据都会生成一条insert undo log，并且数据的回滚指针会指向它。undo log会记录undo log的序号、插入主键的列和值...，那么在进行rollback的时候，通过主键直接把对应的数据删除即可。

![ROLL_PTR_Undo_Log1](https://raw.githubusercontent.com/chen-1110/image/main/ROLL_PTR_Undo_Log1.png)

**当我们执行UPDATE时：**

对于更新的操作会产生update undo log，并且会分更新主键的和不更新主键的，假设现在执行:

```mysql
UPDATE user SET name= "Sun" WHERE id=1;
```

![ROLL_PTR_Undo_Log2](https://raw.githubusercontent.com/chen-1110/image/main/ROLL_PTR_Undo_Log2.png)

### 3.3 binlog

sql改动的逻辑日志，和undolog一样是逻辑日志，和redolog一样是顺序写的，在事务提交后写入，主要用来主从复制和数据复制

dba总说，删库后能够将mysql恢复到30天前的任一时刻，利用的就是binlog，因为binlog默认存30天，比如要回到昨天下午3点钟，在数据库每日备份的前提下，可以先取昨天凌晨备份的副本，再逐条执行binlog，可以借助mysqlbinlog工具

mysql体系的日志，任何引擎都会有

#### **binlog和redolog能不能替换/代替：**

不能，首先从历史设计上，binlog是mysql自带的，和引擎无关，redolog是innodb引擎独有的。

其次从功能角度，两者功能随类似但大有不同，

binlog无法替代redolog，因为binlog记录的是逻辑sql指令，当mysql崩溃时，磁盘数据页可能写了一般发生损坏无法读取，需要redolog的数据页物理记录来恢复

redolog无法替代binlog，因为即使是相同的sql行为，在不同的数据库实例下，会因为读写压力不同，硬件水平不同而发生不同的页分裂行为，利用redolog的页记录做主从复制必然会出错

#### binlog和redolog的两阶段提交

因为binlog的存在，redolog被迫需要设计一个两阶段提交流程，为什么呢？因为我们需要保证redolog和binlog的写入是一个原子操作，不然的话就可能出现，事务提交某一数据库实例崩溃后，redolog写了，binlog没写，节点通过redolog恢复后的数据和其他数据库实例数据不一致，反之亦然。

> 两阶段提交是保证两个操作在可能宕机等极端情况下原子进行的常见方案，其设计思想是
>
> 1.操作A先完成操作，设置状态为prepare
>
> 2.操作B完成操作，设置为完成
>
> 3.操作A将状态设置为commit状态
>
> 流程结束后检查操作A状态，若为commit正常，若为prepare则检查操作B是否完成，若未完成回滚操作A，若完成将操作A设为commit

![image-20251201171455382](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201171455382.png)

> 这里我划掉了prepare和commit的redolog里的redolog记录内容，这是宋红康老师应该备课紧急的错误，prepare和commit里并不会有redolog本身记录（行数据记录），行数据记录在其另外的redolog buffer里，随后台线程或事务提交prepare阶段会单独刷到redolog file，并不与事务prepare的redolog同一结构体写入

![image-20251201172054685](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201172054685.png)

### 3.4 其他日志

慢查询日志

error log

relay log： 主从复制，收到binlog先存到relay log里



## 四、事务

### 4.1 基础知识

事务是指一组逻辑操作，同时成功或同时失败，且多个事务之前互不影响

#### 事务的acid属性

原子性：一组操作要么同时成功，要么同时失败

一致性：一组操作结束后应该逻辑一致，不会出现逻辑错误

持久性：事务提交后的操作永久保存，不会丢失

隔离性：多个事务之前不会互相影响

#### 事务的隔离级别

多个事务操作同一行数据会存在的问题：

1.脏写：事务A修改某一行数据后，事务B再次对该数据进行修改提交，事务A提交后其修改无效

由于脏写影响太过恶劣，所有隔离级别已经对脏写做了处理，在事务B修改同一行数据时会被锁住，待事务A提交后才能继续操作

2.脏读：事务B修改行数据未提交，事务A开启读取该行数据，读取到了事务B的修改后数据

读未提交隔离级别会出现脏读问题，其他隔离级别不会

3.不可重复读：事务A读取某一行数据后，事务B对该数据进行修改提交，事务A再在读取该行数据，读取到了事务B修改后的数据

读未提交，读已提交会出现不可重复读问题，其他不会

4.幻读：事务A按照某查询条件查询数据数量，事务B新增了一些数据后，事务A再次以相同的查询条件查询，两次查询结果不一致

读未提交，读已提交，可重复读会出现幻读问题，串行化不会

ps.这是sql层面的定义（例如Oracle如此），但是mysql的innodb引擎利用其实现特性在可重复读隔离级别下也部分解决了幻读问题（两次读结果一样，但是insert的时候报错主键冲突），mysql的默认隔离级别也是可重复读

#### 示例

初始化数据：

```mysql
TRUNCATE TABLE account;
INSERT INTO account VALUES (1,'张三','100'), (2,'李四','0');
```

表中的数据如下：

```mysql
mysql> select * from account;
+----+------+---------+
| id | name | balance |
+----+------+---------+
|  1 | 张三  | 100.00  |
|  2 | 李四  | 0.00    |
+----+------+---------+
```

**演示1. 读未提交之脏读**

设置隔离级别为未提交读：

![dirty_read_demo](https://raw.githubusercontent.com/chen-1110/image/main/dirty_read_demo.png)

脏读就是指当前事务就在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问了这个数据，然后使用了这个数据。

**演示2：读已提交和不可重复读**

![read_committed_demo](https://raw.githubusercontent.com/chen-1110/image/main/read_committed_demo.png)

**演示3. 可重复读**

设置隔离级别为可重复读，事务的执行流程如下：

![repeatable_read_demo](https://raw.githubusercontent.com/chen-1110/image/main/repeatable_read_demo.png)

当我们将当前会话的隔离级别设置为可重复读的时候，当前会话可以重复读，就是每次读取的结果集都相同，而不管其他事务有没有提交。但是在可重复读的隔离级别上会出现幻读的问题。

**演示4：幻读**

![image-20241007024538425](https://raw.githubusercontent.com/chen-1110/image/main/image-20241007024538425.png)

这里要灵活的理解读取的意思，第一次select是读取，第二次的insert其实也属于隐式的读取，只不过是在mysql的机制中读取的，插入数据也是要先读取一下有没有主键冲突才能决定是否执行插入。

幻读，并不是说两次读取获取的结果集不一样，幻读侧重的方面是某一次的select操作得到的结果所表征的数据状态无法支持接后续的业务操作。更为具体一些：select某记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已经存在，无法插入，此时就发生了幻读。

在RR隔离级别下，step1，step2是会正常执行的，step3则会抛出主键冲突，对于事务1的业务来说是执行失败的，这里事务1就是发生了幻读，因为事务1在step1中读取的数据状态并不能支撑后续的业务操作，事务1：“见鬼了，我刚才读到的结果应该可以支持我这样操作，为什么现在不可以”。事务1不敢相信的又执行了step4，发现和step1读取的结果是一样的（RR下的MVCC机制）。此时，幻读无疑已经发生，事务1无论读取多少次，都查不到 id = 3 的记录，但它的确无法插入这条他通过读取来认定不存在的记录（此数据已被事务2插入），对于事务1来说，它幻读了。

### 4.2 锁

#### 4.2.1高屋建瓴

保障事务的隔离性有两种办法，其一是隐式的设置合适的隔离级别，innodb会自行为你做好隔离性保障（mvcc，下一节讲），其二是显式的在sql语句加锁，通过加锁操作可以更自由更细粒度地做数据隔离安全控制，当然相较mvcc的无锁性能会略差

sql的写操作会隐式自动加锁，读操作根据我们需要可以显式的加锁

（显式锁只在读-写场景有勇武之地，写-写场景会有隐式锁，读-读场景无需锁）

#### 4.2.2有哪些锁

因为mysql里的锁太多了，我们需要先整体看一下，再去看细节，首先从锁的是否共享角度，分为读锁和写锁两种，然后从锁的粒度来看，分为表锁，页锁，行锁三种（二者都有各自的读锁和写锁），我们平时最多的显式使用场景是行锁，然后行锁也分很多种，**mysql的行锁底层都是临键锁**，只不过在不同的场景下，该锁会转化为记录锁及间隙锁。

##### 读写锁

读锁也称为share锁，并发读不互斥，读写互斥

写锁也成为exclusive锁（X锁），读写互斥，写写互斥

举例：

行的读锁SELECT ... LOCK IN SHARE MODE;

行的写锁SELECT ... FOR UPDATE;

另外写操作均为写锁

##### 表锁，页锁，行锁

表锁显式使用很少，在修改表结构时会隐式加元数据锁（MDL锁），此时所有行的增删改查会被阻塞。（所以一般大厂的DDL底层都是通过复制一张新表然后改名来实现的）

页锁使用很少，略

重点在于行锁，mysql的行锁实现都是临键锁（next-key lock），只是在特定场景会退化为记录锁和间隙锁，临键锁是一种左开右闭的区间，**可以认为innodb会对所有扫描的行范围加上临键锁，只要记住这句黄金口诀就好了**。（笔者也不太理解为啥强调底层都是临键锁，可能底层实现如此）

创建学生表student，并插入数据，用于讲解以下行锁

```mysql
CREATE TABLE student (
	id INT,name VARCHAR(20) ,
    class varchar(10) ,
    PRIMARY KEY (id)
) Engine=InnoDB CHARSET=utf8;
```

```mysql
INSERT INTO student VALUES 
(1,'张三','一班'),
(3,'李四','一班') ,
(8,'王五','二班') ,
(15,'赵六','二班') ,
(20,'钱七','三班');
```

**临键锁退化为记录锁**

当查询主键存在时，临键锁退化为记录锁，举例如下：

![image-20251201192613345](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201192613345.png)

设置非自动提交事务；在会话1中更新id=1的记录但不提交；

在会话2中更新id=3的记录，没有被阻塞。

在会话2中更新id=1的记录，被阻塞，超时后再次发出更新请求，此时会话1提交事务，会发现会话2中的语句解除了阻塞。这说明只有id=1的记录被锁定了，也就是只锁定了一条记录。

**临键锁退化为间隙锁**

SELECT * FROM student WHERE id=5 LOCK IN SHARE MODE;

![image-20251201193038212](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201193038212.png)

当另外一个事务再想插入一条id值为4的新记录，它定位到该条新记录的下一条记录的id值为8，而这条记录上又有一个gap锁，所以就会阻塞插入操作，直到拥有这个gap锁的事务提交之后，id列的值在区间(3,8)中的新记录才可以被插入。

无论读锁写锁，间隙锁之间并不会互斥，只会对写操作互斥

间隙锁可能会引来死锁，如下：

| 会话1                                                        | 会话2                                                    |
| ------------------------------------------------------------ | -------------------------------------------------------- |
| BEGIN;<br>SELECT * FROM student WHERE id =5 FOR UPDATE;      | BEGIN;<br/>SELECT * FROM student WHERE id =5 FOR UPDATE; |
|                                                              | INSERT INTO student VALUES(5,'test','二班');#阻塞        |
| INSERT INTO student VALUES(5,'test','二班');#阻塞<br>`ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction` | 插入语句执行成功                                         |

1. 会话 1 执行 `SELECT...FOR UPDATE` 语句，由于 `id=5` 的记录并不存在，因此会加上间隙锁（3,8）。
2. 会话 2 执行 `SELECT...FOR UPDATE` 语句，同样会加上间隙锁（3,8）。由于间隙锁之间不会产生冲突，因此这条语句可以执行成功。
3. 会话 2 试图插入一条 `id=5` 的记录，被会话 1 的间隙锁阻塞了，只好进入等待状态。
4. 会话 1 试图插入一条 `id=5` 的记录，被会话 2 的间隙锁阻塞了，也只好进入等待状态。

至此，两个会话进入互相等待状态，产生了死锁。当然，`InnoDB` 存储引擎中的死锁检测机制马上就会检测到这对死锁关系，会话 1 中的 `INSERT` 语句会返回报错信息。会话 2 中的语句返回插入成功的信息。

##### 显示锁/隐式锁

较典型的隐式锁是，写操作默认情况下是无锁的，当其他事务加锁读或写同一记录时会帮其生成一个x锁，阻塞其他事物本身

#### 4.2.3 锁的内存结构

![image-20251201194032461](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201194032461.png)

#### 4.2.4 通用加锁判断规则

innodb不认where条件，仅看扫描了哪些索引范围，想象为一个左开右闭区间的临键锁不断向左滑动，底层的原则是要将可能出问题的b+树位置都锁住不让后来者插入（若是没有索引则会锁全表）

##### 唯一索引vs非唯一索引

唯一索引等值查询，若记录存在会退化为记录锁，若记录不存在退化为间隙锁

非唯一索引等值查询，若记录存在，锁等值记录和最右区间间隙锁;

​	若记录不存在,退化为间隙锁

唯一索引范围查询，>=相当于>加=，=规则同上，大小比较的范围查询，退化为间隙锁

非唯一索引范围查询，如果查询的值存在加临建锁，右区间加间隙锁，查询的值不存在，降级为间隙锁，不等值查询，碰到第一个不满足的索引记录时，加临键锁

##### SELECT语句设置的锁

`SELECT ... FROM`，它是一个一致性读取，会读取数据库的快照，读取的过程中，忽略读取视图中存在的记录上的任何锁。并且不会设置任何锁。除非事务隔离级别设置为`SERIALIZABLE`。在 `SERIALIZABLE` 级别下，搜索会对其遇到的索引记录设置共享的临键锁。对于使用唯一索引来查找唯一行的语句，只添加记录锁。

`SELECT ... FOR UPDATE` 和 `SELECT ... FOR SHARE` 语句在使用唯一索引时会为扫描到的行获取锁，并对不符合结果集条件的行（例如不满足 WHERE 子句中的条件）释放锁。

<b>主键索引和二级索引加锁情况</b>

`SELECT ... FOR UPDATE`  在对二级索引加锁的同时，会对主键索引加锁。二级索引上如果加了临键锁，回表到主键索引加的是行锁。

`SELECT ... FOR SHARE`   如果是覆盖索引，则只在二级索引上加锁，不会对主键索引加锁。二级索引上如果加了临键锁，回表到主键索引加的是行锁。

> 注意：在某些情况下，由于在查询执行过程中结果行与其原始来源的关系丢失，行可能不会立即解锁。
>
> 例如，在 `UNION` 中，从表中扫描（并锁定）的行可能会在插入临时表后才被评估是否符合结果集条件。在这种情况下，临时表中的行与原始表中的行之间的关系丢失，因此原始表中的行在查询执行结束之前不会被解锁。

##### UPDATE语句设置的锁

`UPDATE ... WHERE ...` 会对搜索遇到的每个记录设置独占的临键锁。

唯一索引等值查询，情况同通用规则。查询记录存在，临键锁退化为独占的记录锁。查询记录不存在，临键锁退化为独占的间隙锁。

当 `UPDATE` 修改聚簇索引记录时，会对受影响的二级索引记录隐式加锁。

`UPDATE` 修改唯一索引时，需要删除旧的索引，插入新的索引。旧的索引记录上会加上记录锁，插入的新索引记录则隐式加锁。`加锁的逻辑 = DELETE操作 + INSERT操作`。

在唯一索引上插入新的索引记录之前，`UPDATE` 操作还会在执行重复检查扫描时对受影响的索引记录加共享锁。

##### DELETE语句设置的锁

`DELETE FROM ... WHERE ...` 对搜索遇到的每个记录设置独占的临键锁。

唯一索引等值查询，情况同通用规则。查询记录存在，临键锁退化为独占的记录锁。查询记录不存在，临键锁退化为独占的间隙锁。

##### INSERT语句设置的锁

参考插入意向锁和隐式锁

普通INSERT语句，只有隐式锁，参考隐式锁章节。

当插入的间隙，存在意向锁的时候，则去获取插入意向锁。参考插入意向锁章节。

> ## 附录
>
> **间隙锁加锁规则（共11个案例）**
>
> 间隙锁是在可重复读隔离级别下才会生效的：`next-key lock`实际上是由间隙锁加行锁实现的，如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。而**在读提交隔离级别下**间隙锁就没有了，**为了解决可能出现的数据和日志不一致问题，需要把binlog 格式设置为 row **。也就是说，许多公司的配置为：读提交隔离级别加 `binlog_format=row`。业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。
>
> <b>next-key lock的加锁规则</b>
>
> 总结的加锁规则里面，包含了两个原则、两个优化。
>
> * 原则1 ：加锁的基本单位是`next-key lock`。`next-key lock`是前开后闭区间。
> * 原则2 ：查找过程中访问到的对象才会加锁。
> * 优化1 ：索引上的等值查询，给唯一索引加锁的时候，`next-key lock`退化为行锁。
> * 优化2 ：索引上的等值查询，给非唯一索引加锁的时候，向右遍历时且最后一个值不满足等值条件的时候， `next-keylock`退化为间隙锁。
>
> 我们以表test作为例子，建表语句和初始化语句如下：其中id为主键索引
>
> ```mysql
> CREATE TABLE `test` (
>     `id` int(11) NOT NULL,
>     `col1` int(11) DEFAULT NULL,
>     `col2` int(11) DEFAULT NULL,
>     PRIMARY KEY (`id`),
>     KEY `c` (`col1`)
> ) ENGINE=InnoDB;
> insert into test values(0,0,0),(5,5,5),
> (10,10,10),(15,15,15),(20,20,20),(25,25,25);
> ```
>
> #### 案例1：唯一索引等值查询
>
> | sessionA                                            | sessionB                                     | sessionC                                                  |
> | --------------------------------------------------- | -------------------------------------------- | --------------------------------------------------------- |
> | begin;<br>update test set col2 = col2+1 where id=7; |                                              |                                                           |
> |                                                     | insert into test  values(8,8,8)<br>(blocked) |                                                           |
> |                                                     |                                              | update test set col2 = col2+1 where id=10;<br/>(Query OK) |
>
> sessionA 唯一索引等值查询，查询的记录不存在，临键锁退化为间隙锁，锁定间隙(5,10)，因为是Update操作，所以设置是独占的间隙锁。
>
> sessionC 唯一索引等值查询，查询的记录存在，临键锁退化为记录锁，只锁定一条记录id=10。
>
> ```mysql
> *************************** Session A ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:4:4:140058950704768
> ENGINE_TRANSACTION_ID: 122892
>             THREAD_ID: 48
>              EVENT_ID: 16
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: PRIMARY
> OBJECT_INSTANCE_BEGIN: 140058950704768
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 10
> *************************** Session C ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585968:40:4:4:140058950710992
> ENGINE_TRANSACTION_ID: 122896
>             THREAD_ID: 49
>              EVENT_ID: 37
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: PRIMARY
> OBJECT_INSTANCE_BEGIN: 140058950710992
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,REC_NOT_GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 10
> ```
>
> #### 案例2：非唯一索引等值查询
>
> | sessionA                                                     | sessionB                                                | sessionC                                      |
> | ------------------------------------------------------------ | ------------------------------------------------------- | --------------------------------------------- |
> | begin;<br>select id from test where col1 = 5 lock in share mode; |                                                         |                                               |
> |                                                              | update test set col2 = col2+1 where id=5;<br>(Query OK) |                                               |
> |                                                              |                                                         | insert into test values(7,7,7);<br/>(blocked) |
>
> * SessionA 非唯一索引等值查询
>
> 查询的值 col1=5 存在，加临键锁 (0,5]
>
> 因为是非唯一索引，继续向右遍历，直到遇到第一条不满足条件的索引col1=10，临键锁降级为间隙锁(5,10)
>
> 因为是覆盖索引，且是共享锁，并不需要访问主键索引，所以不对主键索引进行加锁
>
> * SessionB 唯一索引等值查询
>
> 因为，SessionA只在索引c上加锁，没有对主键索引进行加锁
>
> 所以 SessionB 对主键索引加锁，不会被阻塞
>
> 如果 SessionA 是 for update，独占锁，会同时对主键索引加行锁，则 SessionB 的操作会被阻塞
>
> * Session C 要插入一个 (7,7,7) 的记录，被 Session A 的间隙锁 (5,10) 锁住
>
> > [!important]
> >
> > 如果要用 lock in share mode来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，因为覆盖索引不会访问主键索引，不会给主键索引上加锁
>
> #### 案例3：唯一索引范围查询1
>
> 上面两个例子是等值查询的，这个例子是关于范围查询的，也就是说下面的语句
>
> ```mysql
> select * from test where id=10 for update
> select * from tets where id>=10 and id<11 for update;
> ```
>
> 这两条查语句肯定是等价的，但是它们的加锁规则不太一样
>
> | sessionA                                                     | sessionB                                                     | sessionC                                            |
> | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------------------- |
> | begin;<br>select * from test where id>=10 and id<11 for update; |                                                              |                                                     |
> |                                                              | insert into test values(8,8,8);<br>(Query OK)<br>insert into test values(13,13,13); (blocked) |                                                     |
> |                                                              |                                                              | update test set col2=col2+1 where id=15; (Query OK) |
>
> 先拆分出等值条件 id = 10，唯一索引等值查询，查询的值存在，降级为行锁。锁住id=10这一行
>
> 因为是范围查询，从左往右遍历，直到遇到第一条不满足查询条件的索引记录id=15，临键锁降级为间隙锁。锁住间隙（10,15)
>
> 最终，session A 锁的范围就是主键索引上，行锁 id=10 和 间隙锁(10,15）。
>
> **首次 session A 定位查找id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。**
>
> #### 案例4：非唯一索引范围查询
>
> 与案例三不同的是，案例四中查询语句的 where 部分用的是字段 col1 ，它是普通索引
>
> 这两条查语句肯定是等价的，但是它们的加锁规则不太一样
>
> ```mysql
> # IX表级锁 索引C上 (5,10] (10,15) 主键索引上 行级锁 10
> select * from test where col1=10 for update; 
> 
> # IX表级锁 索引C上 间隙锁(5,10] (10,15] 主键索引上 行级锁 10
> select * from test where col1>=10 and col1<11 for update;
> ```
>
> | sessionA                                                     | sessionB                                     | sessionC                                                |
> | ------------------------------------------------------------ | -------------------------------------------- | ------------------------------------------------------- |
> | begin;<br>select * from test where col1>=10 and col1<11 for update; |                                              |                                                         |
> |                                                              | insert into test values(8,8,8);<br>(blocked) |                                                         |
> |                                                              |                                              | update test set col2=col2+1 where id=15; <br>(Query OK) |
> |                                                              |                                              | update test set col1=col1+1 where id=15; <br/>(blocked) |
>
> 非唯一索引范围查询，从左往右扫描，直到遇到第一条不满足查询条件的索引记录，扫到的索引记录，全加临键锁。因此锁定的范围是索引c上 (5,10] 和 (10,15]
>
> 同时因为是二级索引上的排他锁，同时需要对主键索引记录，id=10 和 id=15 加行锁。
>
> #### 案例5：唯一索引范围查询锁2
>
> | sessionA                                                     | sessionB                                            | sessionC                                         |
> | ------------------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------ |
> | begin;<br>select * from test where id>10 and id<=15 for update; |                                                     |                                                  |
> |                                                              | update test set col2=col2+1 where id=20; (query ok) |                                                  |
> |                                                              |                                                     | insert into test values(16,16,16);<br>(query ok) |
>
> 拆分条件，拆成 id = 15 和 10<id<15
>
> id=15，唯一索引等值查询，行锁锁定15
>
> 10<id<15，遇到第一个不符合条件的值，15，降级为间隙锁，锁定（10，15）
>
> 因此总的锁定范围为 （10,15] 临键锁
>
> #### 案例6：非唯一索引上存在"等值"的例子
>
> 给表 t 插入一条新记录：`insert into test values(30,10,30);`
>
> 也就是说，现在表里面有两个col1=10的行。但是它们的主键值 id 是不同的（分别是 10 和 30 ），因此这两个col1=10 的记录之间，也是有间隙的。
>
> | sessionA                                  | sessionB                                         | sessionC                                                   |
> | ----------------------------------------- | ------------------------------------------------ | ---------------------------------------------------------- |
> | begin;<br>delete from test where col1=10; |                                                  |                                                            |
> |                                           | insert into test values(12,12,12); <br>(blocked) |                                                            |
> |                                           |                                                  | update test set col2=col2+1 where col1=15; <br/>(query ok) |
>
> 这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select ... for update 是类似的。
>
> 这时，session A 在遍历的时候，先访问第一个 col1=10 的记录。同样地，根据原则 1 ，这里加的是
> (col1=5,id=5) 到 (col1=10,id=10) 这个 next-key lock 。
>
> 由于c是普通索引，所以继续向右查找，直到碰到 (col1=15,id=15) 这一行循环才结束。根据优化 2 ，这是
> 一个等值查询，向右查找到了不满足条件的行，所以会退化成 (col1=10,id=10) 到 (col1=15,id=15) 的间隙锁。
>
> ![lock_demo6](https://raw.githubusercontent.com/chen-1110/image/main/lock_demo6.png)
>
> 这个 delete 语句在索引 c 上的加锁范围，就是上面图中蓝色区域覆盖的部分。这个蓝色区域左右两边都
> 是虚线，表示开区间，即 (col1=5,id=5) 和 (col1=15,id=15) 这两行上都没有锁
>
> 在`非聚簇索引`上，锁住(col1=5,id=5) 到 (col1=15,id=15)
>
> 在`聚簇索引`上，只锁住 col=10 的那两行
>
> #### 案例7：limit语句加锁
>
> 例子6也有一个对照案例，场景如下所示：
>
> | sessionA                                           | sessionB                                          |
> | -------------------------------------------------- | ------------------------------------------------- |
> | begin; <br>delete from test where col1=10 limit 2; |                                                   |
> |                                                    | insert into test values(12,12,12); <br>(Query OK) |
>
> session A 的 delete语句加了 limit 2。你知道表 t里 c=10的记录其实只有两条，因此加不加 limit2，删除的效果都是一样的。但是加锁效果却不一样
>
> 这是因为，案例七里的 delete语句明确加了 limit2的限制，因此在遍历到 (col1=10,id=30)这一行之后， 满足条件的语句已经有两条，循环就结束了。因此，索引 col1上的加锁范围就变成了从（col1=5,id=5) 到（col1=10,id=30)这个前开后闭区间，如下图所示：
>
> ![lock_demo7](https://raw.githubusercontent.com/chen-1110/image/main/lock_demo7.png)
>
> 这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。 
>
> 这样不仅可以**控制删除数据的条数，让操作更安全，还可以减小加锁的范围。**
>
> 
>
> ```mysql
> select col1 from test where col1 = 5 for share;
> select col1 from test where col1 = 5  limit 1 for share;
> select col1 from test where col1 = 5  limit 2 for share;
> ```
>
> 语句1：没有limit的情况下，索引C上锁定范围 （0,5] (5,10)
>
> 语句2：存在limit的情况下，索引C上锁定范围 (0,5] ，limit限制只扫描一条，不需要再继续向扫描了。
>
> 语句3：存在limit的情况下，索引C上锁定范围 （0,5] (5,10) 因为limit要扫两条，找不到第二条，一直扫到遇上第一条不符合的记录为止，临键锁降级为间隙锁。
>
> #### 案例8：一个死锁的例子
>
> | sessionA                                                     | sessionB                                                     |
> | ------------------------------------------------------------ | ------------------------------------------------------------ |
> | begin;<br>select id from test where col1=10 lock in share mode; |                                                              |
> |                                                              | update test set col2=col2+1 where col1=10;<br>(blocked)      |
> | insert into test values(8,8,8);                              |                                                              |
> |                                                              | ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction |
>
> * sessionA启动事务后执行查询语句加 lock in share mode，在索引col1上加了next-keylock(5,10]和间隙锁 (10,15)（索引向右遍历退化为间隙锁）；
> * sessionB的update语句也要在索引c上加next-keylock(5,10]，进入锁等待；实际上分成了两步，先是加 (5,10)的间隙锁，加锁成功；然后加col1=10的行锁，因为sessionA上已经给这行加上了读锁，此时申请死锁时会被阻塞
> * sessionA要再插入(8,8,8)这一行，被 sessionB的间隙锁锁住。由于出现了死锁，InnoDB让 sessionB回滚
>
> #### 案例9：order by索引排序的间隙锁1
>
> 如下面一条语句
>
> ```mysql
> begin;
> # 正序情况下，锁定(5,10]  (10,15]
> select * from test where id>9 and id<12 order by id  for update;
> 
> # 下面的解释是倒叙
> select * from test where id>9 and id<12 order by id desc for update;
> ```
>
> 下图为这个表的索引id的示意图。
>
> ![lock_demo9](https://raw.githubusercontent.com/chen-1110/image/main/lock_demo9.png)
>
> 首先这个查询语句的语义是 order by id desc ，要拿到满足条件的所有行，优化器必须先找到第一个 id<12 的值。
>
> 这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id=12 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙。id=15 不满足条件，所以 next-key lock 退化为了间隙锁 (10,15)
>
> 然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id=5 这一行，又因为区间是左开右
> 闭的，所以会加一个next-key lock (0,5] 。 也就是说，在执行过程中，通过树搜索的方式定位记录
> 的时候，用的是 “ 等值查询 ” 的方法。
>
> #### 案例10：order by索引排序的间隙锁2
>
> | sessionA                                                     | sessionB                                               |
> | ------------------------------------------------------------ | ------------------------------------------------------ |
> | begin;<br>select * from test where col1>=15 and col1<=20 order by col1 desc lock in share mode; |                                                        |
> |                                                              | insert into test values(6,6,6);<br>(blocked)           |
> |                                                              | insert into test values(11,11,11);<br/>(blocked)       |
> |                                                              | update test set col2 = col2 +1 where id =10;(Query OK) |
> |                                                              | update test set col2 = col2 +1 where col1=10;(blocked) |
>
> * 由于是order by col1 desc，第一个要定位的是索引col1上最右边的col1=20的行。这是一个非唯一索引的等值查询：
>
>   左开右闭区间，首先加上 next-keylock(15,20]。向右遍历，col1=25不满足条件，退化为间隙锁所以会 加上间隙锁(20,25)和 next-keylock(15,20]。
>
> * 在索引 col1 上向左遍历，要扫描到 col1=10 才停下来。同时又因为左开右闭区间，所以 next-key lock会加到 (10,15]，这正是阻塞 session B 的 insert into test values(11,11,11)语句的原因。
>
> * 在扫描过程中，col1=20、col1=15、col1=10这三行都存在值，由于是 select *，所以会在主键id上加上行锁。因此，session A的 select语句锁的范围就是：
>
> * * 索引 c 上 (5,10] (10,15] (15,20]（20,25) ；
>   * 主键索引上 id=15、20两个行锁。
>
> #### 案例11：update的例子
>
> 当 `UPDATE` 修改聚簇索引记录时，会对受影响的二级索引记录隐式加锁。
>
> | sessionA                                     | sessionB                                      |
> | -------------------------------------------- | --------------------------------------------- |
> | begin;<br>update test set col1=1 where id=5; |                                               |
> |                                              | update test set col1=5 where col1=1;(blocked) |
>
> SessionA执行Update语句，唯一索引等值查询，会在聚簇索引上加一条行锁，锁id=5这条记录
>
> 在二级索引C上，并没有显示的加锁
>
> ```mysql
> *************************** row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:4:3:140058950704768
> ENGINE_TRANSACTION_ID: 122988
>             THREAD_ID: 63
>              EVENT_ID: 21
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: PRIMARY
> OBJECT_INSTANCE_BEGIN: 140058950704768
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,REC_NOT_GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 5
> ```
>
> SessionB尝试修改二级索引，导致二级索引上的隐式锁，变为记录锁
>
> ```mysql
> *************************** row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:4:3:140058950704768
> ENGINE_TRANSACTION_ID: 122988
>             THREAD_ID: 63
>              EVENT_ID: 21
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: PRIMARY
> OBJECT_INSTANCE_BEGIN: 140058950704768
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,REC_NOT_GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 5
> *************************** 隐式锁变成记录锁 ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:5:8:140058950705112
> ENGINE_TRANSACTION_ID: 122988
>             THREAD_ID: 64
>              EVENT_ID: 13
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: c
> OBJECT_INSTANCE_BEGIN: 140058950705112
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,REC_NOT_GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 1, 5
> ```
>
> 
>
> #### 案例12 Update例子——非唯一索引上的操作
>
> | Session A                                     | SessionB |
> | --------------------------------------------- | -------- |
> | begin<br>update test set col1=4 where col1=5; |          |
> |                                               |          |
>
> 非唯一索引等值查询，col1=5存在，索引C上锁定范围 （0,5] （5,10）
>
> 插入新的二级索引col1=4，锁定范围（0,4)
>
> ```mysql
> *************************** 2. row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:5:3:140058950704768
> ENGINE_TRANSACTION_ID: 123017
>             THREAD_ID: 63
>              EVENT_ID: 74
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: c
> OBJECT_INSTANCE_BEGIN: 140058950704768
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 5, 5
> *************************** 3. row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:4:3:140058950705112
> ENGINE_TRANSACTION_ID: 123017
>             THREAD_ID: 63
>              EVENT_ID: 74
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: PRIMARY
> OBJECT_INSTANCE_BEGIN: 140058950705112
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,REC_NOT_GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 5
> *************************** 4. row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:5:4:140058950705456
> ENGINE_TRANSACTION_ID: 123017
>             THREAD_ID: 63
>              EVENT_ID: 74
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: c
> OBJECT_INSTANCE_BEGIN: 140058950705456
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 10, 10
> *************************** 5. row ***************************
>                ENGINE: INNODB
>        ENGINE_LOCK_ID: 140059072585112:40:5:8:140058950705456
> ENGINE_TRANSACTION_ID: 123017
>             THREAD_ID: 63
>              EVENT_ID: 74
>         OBJECT_SCHEMA: dbtest_lock
>           OBJECT_NAME: test
>        PARTITION_NAME: NULL
>     SUBPARTITION_NAME: NULL
>            INDEX_NAME: c
> OBJECT_INSTANCE_BEGIN: 140058950705456
>             LOCK_TYPE: RECORD
>             LOCK_MODE: X,GAP
>           LOCK_STATUS: GRANTED
>             LOCK_DATA: 4, 5
> ```
>
> >唯一索引的话，update操作，删除的记录加行锁，新的记录加隐式锁

### 4.3 MVCC

技术上的很多东西都是名头高大上，实际内容只值5分钱，笔者在接触数据库很长时间内，对于MVCC都是敬而远之，莫名觉得很nb高深，乃至最终走了很长的路才去学习它，学习的时候也是调整了很久心态，试图以最大的思维凝聚力去理解，但实际学习下来，根本不是很困难，甚至不怎么需要脑力思考，ok闲话到此我们继续来看MVCC吧

MVCC是innodb隐式实现不同隔离级别的底层方式，实际是做了啥呢，事务中我们会修改某条数据，mvcc的做法就是把修改前的数据记录下来（广义的，实际上是记录了undolog），不同的事务在读该条记录的时候，通过undolog读到不同的结果。

##### MVCC具体实现

mvcc具体实现依赖事务id，undolog，read veiw

**readView**

readView字面含义，是一个视图，这个视图存储的什么呢，是当前生成视图时所有活跃未提交事务的id，具体的来说，其有4个重要数据组成

trx_ids:如刚才所说，所有活跃未提交事务的id

creator_trx_id：创建readView事务自身的事务id

up_limit_id: trx_ids里面最小的id

low_limit_id: 整个mysql下一次要分配的事务id(事务id是递增的)，这个id不一定是trx_ids的id最大值，因为可能更大的事务id已经在此刻提交了（后开启早提交）

刚才我们讲过undolog了，还记得行记录隐藏列的几个字段吧，trx_id事务id,roll_pointer（undolog的指针）忘记的去看3.2节。假设有多个事务提交修改了同一条数据，如下图

![image-20251201204054317](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201204054317.png)

当另一个事务取该行记录时，会遍历它的roll_pointer，讲roll_pointer里的undolog的trx_id(事务id)与自己的readView比较，

1.当trx_id等于creator_trx_id时，说明该undolog是自身事务修改导致的，可以访问跳到下一条

2.当trx_id小于up_limit_id时，说明该undolog导致的事务已提交，可以访问跳到下一条（这就是读已提交，可能有人会疑问可重复读不应该读不到这个改动吗，后面会将可重复读是只在第一次查询生成readView，就能做到重复读了，读已提交是每次生成readView所以能读到最新的提交从而不可重复读）

3.当trx_id大于low_limit_id，说明该undolog的事务是在当前事务生成readView后才开启，不可访问

4.当trx_id在up_limit_id和low_limit_id之间，判断其是否在trx_ids列表里，若在列表里说明生成readView时还活跃，不可被访问。若不在列表说明生成时已提交，可以被访问。

> ##### 举例说明
>
> 假设现在student表中只有一条由事务id为8的事务插入的一条记录:
>
> ```mysql
> mysql> select *from student;
> +----+--------+--------+
> | id | name   | class  |
> +----+--------+--------+
> |  1 | 张三   | 一班    |
> +----+--------+--------+
> ```
>
> MVCC只能在READ COMMITTED和REPEATABLE READ两个隔离级别下工作。接下来看一下`READ COMMITTED`和`REPEATABLE READ`所谓的生成ReadView的时机不同到底不同在哪里。
>
> ###### READ COMMITTED隔离级别下
>
> **READ COMMITTED** **：每次读取数据前都生成一个ReadView**。
>
> 现在有两个事务id分别为`10`、`20`的事务在执行：
>
> ```mysql
> # Transaction 10
> BEGIN;
> UPDATE student SET name="李四" WHERE id= 1 ;
> UPDATE student SET name="王五" WHERE id= 1 ;
> 
> # Transaction 20
> BEGIN;
> # 更新了一些别的表的记录
> ...
> ```
>
> >说明:事务执行过程中，只有在第一次真正修改记录时（比如使用INSERT、DELETE、UPDATE语句)，才会被分配一个单独的事务id，这个事务id是递增的。所以我们才在事务2中更新些别的表的记录，目的是让它分
> >配事务id。
>
> 此刻，表student 中`id为1的记录`得到的版本链表如下所示：
>
> ![MVCC_Undo_Log_Demo2](https://raw.githubusercontent.com/chen-1110/image/main/MVCC_Undo_Log_Demo2.jpg)
>
> 假设现在有一个使用READ COMMITTED隔离级别的事务开始执行：
>
> ```mysql
> # 使用READ COMMITTED隔离级别的事务
> BEGIN;
> 
> # SELECT1：Transaction 10、 20 未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值为'张三'
> ```
>
> 这个`SELECT1`的执行过程如下:
>
> 步骤1: 在执行SELECT语句时会先生成一个`ReadView`, ReadView的`trx_ids`列表的内容就是`[10，20]`，`up_limit_id`为10, `low_limit_id`为21, `creator_trx_id`为0。
>
> 步骤2:从版本链中挑选可见的记录，从图中看出，最新版本的列`name`的内容是'`王五`'，该版本的`trx_id`值为`10`，在`trx_ids`列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。
>
> 步骤3:下一个版本的列`name`的内容是'`李四`'，该版本的`trx_id`值也为`10`，也在`trx_ids`列表内，所以也不符合要求，继续跳到下一个版本。
>
> 步骤4:下一个版本的列`name`的内容是'`张三`'，该版本的`trx_id`值为8，小于ReadView中的`up_limit_id`值`10`，所以这个版本是符合要求的，最后返回给用户的版本就是这条列`name`为‘`张三`'的记录。
>
> 之后，我们把`事务id`为 `10` 的事务提交一下：
>
> ```mysql
> # Transaction 10
> BEGIN;
> 
> UPDATE student SET name="李四" WHERE id= 1 ;
> UPDATE student SET name="王五" WHERE id= 1 ;
> 
> COMMIT;
> ```
>
> 然后再到事务id为 20 的事务中更新一下表student中id为 1 的记录：
>
> ```mysql
> # Transaction 20
> BEGIN;
> 
> # 更新了一些别的表的记录
> ...
> UPDATE student SET name="钱七" WHERE id= 1 ;
> UPDATE student SET name="宋八" WHERE id= 1 ;
> ```
>
> 此刻，表student中id为 1 的记录的版本链就长这样：
>
> ![image-20251201205358872](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201205358872.png)
>
> 然后再到刚才使用`READ COMMITTED`隔离级别的事务中继续查找这个id为 1 的记录，如下：
>
> ```mysql
> # 使用READ COMMITTED隔离级别的事务
> BEGIN;
> 
> # SELECT1：Transaction 10、 20 均未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值为'张三'
> 
> # SELECT2：Transaction 10提交，Transaction 20未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值为'王五'
> ```
>
> 这个`SELECT2`的执行过程如下:
>
> 步骤1:在执行`SELECT`语句时会又会单独生成一个`ReadView`，该ReadView的trx_ids列表的内容就是[`20`],`up_limitid`为20,`low_limit_id`为21, `creator_trx_id`为`0`。
>
> 步骤2:从版本链中挑选可见的记录，从图中看出，最新版本的列`name`的内容是‘`宋八`‘，该版本的`trx_id`值为20，在`trx_ids`列表内，所以不符合可见性要求，根据`roll_pointer`跳到下一个版本。
>
> 步骤3:下一个版本的列`name`的内容是‘`钱七`'，该版本的`trx_id`值为`20`，也在`trx_ids`列表内，所以也不符合要求，继续跳到下一个版本。
>
> 步骤4:下一个版本的列`name`的内容是'`王五`'，该版本的`trx_id`值为10，小于`ReadView`中的`up_limit_id`值20，所以这个版本是符合要求的，最后返回给用户的版本就是这条列`name`为‘`王五`‘的记录。
>
> 以此类推，如果之后事务id为20的记录也提交了，再次在使用READ COMMITTED隔离级别的事务中查询表student中id值为1的记录时，得到的结果就是‘宋八'了，具体流程我们就不分析了。
>
> > 强调: 使用READ COMMITTED隔离级别的事务在每次查询开始时都会生成一个独立的ReadView。 
>
> ###### REPEATABLE READ隔离级别下
>
> 使用`REPEATABLE READ`隔离级别的事务来说，只会在第一次执行查询语句时生成一个 `ReadView` ，之后的查询就不会重复生成了。
>
> 比如，系统里有两个事务id分别为 10 、 20 的事务在执行：
>
> ```mysql
> # 开始记录
> mysql> select *from student;
> +----+--------+--------+
> | id | name   | class  |
> +----+--------+--------+
> |  1 | 张三    | 一班   |
> +----+--------+--------+
> ```
>
> ```mysql
> # Transaction 10
> BEGIN;
> UPDATE student SET name="李四" WHERE id= 1 ;
> UPDATE student SET name="王五" WHERE id= 1 ;
> 
> # Transaction 20
> BEGIN;
> # 更新了一些别的表的记录
> ...
> ```
>
> 此刻，表student 中id为 1 的记录得到的版本链表如下所示：
>
> ![image-20251201205528329](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201205528329.png)
>
> 假设现在有一个使用`REPEATABLE READ`隔离级别的事务开始执行：
>
> ```mysql
> # 使用REPEATABLE READ隔离级别的事务
> BEGIN;
> 
> # SELECT1：Transaction 10、 20 未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值为'张三'
> ```
>
> 这个SELECT1的执行过程如下（`第一个ReadView和读已提交是一样的)`:
>
> 步骤1: 在执行SELECT语句时会先生成一个`ReadView` , ReadView的 `trx_ids`列表的内容就是`[10，20]`，`up_limit_id`为10, `low_limit_id`为21, `creator_trx_id`为0。
>
> 步骤2:从版本链中挑选可见的记录，从图中看出，最新版本的列`name`的内容是'`王五`'，该版本的`trx_id`值为`10`，在`trx_ids`列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。
>
> 步骤3:下一个版本的列`name`的内容是'`李四`'，该版本的`trx_id`值也为`10`，也在`trx_ids`列表内，所以也不符合要求，继续跳到下一个版本。
>
> 步骤4:下一个版本的列`name`的内容是'`张三`'，该版本的`trx_id`值为8，小于ReadView中的`up_limit_id`值`10`，所以这个版本是符合要求的，最后返回给用户的版本就是这条列`name`为‘`张三`'的记录。
>
> 之后，我们把`事务id`为`10`的事务提交一下：
>
> ```mysql
> # Transaction 10
> BEGIN;
> 
> UPDATE student SET name="李四" WHERE id= 1 ;
> UPDATE student SET name="王五" WHERE id= 1 ;
> 
> COMMIT;
> ```
>
> 然后再到事务id为 20 的事务中更新一下表student中id为 1 的记录：
>
> ```mysql
> # Transaction 20
> BEGIN;
> 
> # 更新了一些别的表的记录
> ...
> UPDATE student SET name="钱七" WHERE id= 1 ;
> UPDATE student SET name="宋八" WHERE id= 1 ;
> ```
>
> 此刻，表student 中id为 1 的记录的版本链长这样：
>
> ![image-20251201205554325](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201205554325.png)
>
> 然后再到刚才使用`REPEATABLE READ`隔离级别的事务中继续查找这个id为 1 的记录，如下：
>
> ```mysql
> # 使用REPEATABLE READ隔离级别的事务
> BEGIN;
> 
> # SELECT1：Transaction 10、 20 均未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值为'张三'
> 
> # SELECT2：Transaction 10提交，Transaction 20未提交
> SELECT * FROM student WHERE id = 1 ; # 得到的列name的值仍为'张三'
> ```
>
> 这个`SELECT2`的执行过程如下:
>
> 步骤1:因为当前事务的隔离级别是`REPEATABLE READ`，而之前在执行`SELECT1`时已经生成过ReadView了，所以此时会直接复用之前的`ReadView`，之前的ReadView的trx_ids列表的内容是[10，20]，`up_limit_id`为10, `low_limit_id`为21, `creator_trx_id`为0。
>
> 步骤2:然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列name的内容是'宋八'，该版本的trx_id值为20，在trx_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。
>
> 步骤3:下一个版本的列name的内容是'钱七'，该版本的trx_id值为20，也在trx_ids列表内，所以也不符合要求，继续跳到下一个版本。
>
> 步骤4∶下一个版本的列name的内容是'王五'，该版本的trx_id值为10，而trx_ids列表中是包含值为10的事务id的，所以该版本也不符合要求，同理下一个列name的内容是'李四’的版本也不符合要求。继续跳到下一个版本。
>
> 步骤5∶下一个版本的列name的内容是‘张三'，该版本的trx_id值为80，小于ReadView中的up_limit_id值10，所以这个版本是符合要求的，最后返回给用户的版本就是这条列c为'张三'的记录。
>
>
> 两次SELECT查询得到的结果是重复的，记录的列c值都是'张三'，这就是可重复读的含义。如果我们之后再把事务id为20的记录提交了，然后再到刚才使用REPEATABLE READ隔离级别的事务中继续查找这个id为1的记录，得到的结果还是‘张三'，具体执行过程大家可以自己分析一下。
>
> ###### 如何解决幻读
>
> 接下来说明InnoDB是如何解决幻读的。
>
> 假设现在表 student 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图所示。
>
> ![MVCC_Phantom_Read_Demo](https://raw.githubusercontent.com/chen-1110/image/main/MVCC_Phantom_Read_Demo.jpg)
>
> 假设现在有事务 A 和事务 B 并发执行，`事务 A`的事务 id 为`20`，`事务 B`的事务 id 为`30`。
>
> 
>
> 步骤1：事务 A 开始第一次查询数据，查询的 SQL 语句如下。
>
> ```mysql
> select * from student where id >= 1;
> ```
>
> 在开始查询之前，MySQL 会为事务 A 产生一个 ReadView，此时 ReadView 的内容如下：`trx_ids= [20,30]`，`up_limit_id=20`，`low_limit_id=31`，`creator_trx_id=20`。
>
> 由于此时表 student 中只有一条数据，且符合 where id>=1 条件，因此会查询出来。然后根据ReadView机制，发现该行数据的trx_id=10，小于事务 A 的 ReadView 里 up_limit_id，这表示这条数据是事务 A 开启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。
>
> 结论：事务 A 的第一次查询，能读取到一条数据，id=1。
>
> 
>
> 步骤2：接着事务 B(trx_id=30)，往表 student 中新插入两条数据，并提交事务。
>
> ```mysql
> insert into student(id,name) values(2,'李四'); 
> insert into student(id,name) values(3,'王五');
> ```
>
> 此时表student 中就有三条数据了，对应的 undo 如下图所示：
>
> ![MVCC_Phantom_Read_Demo2](https://raw.githubusercontent.com/chen-1110/image/main/MVCC_Phantom_Read_Demo2.jpg)
>
> 步骤3：接着事务A 开启第二次查询，根据可重复读隔离级别的规则，此时事务A 并不会再重新生成ReadView。此时表 student 中的 3 条数据都满足 where id>=1 的条件，因此会先查出来。然后根据ReadView 机制，判断每条数据是不是都可以被事务 A 看到。
>
> 1）首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。
>
> 2）然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 up_limit_id 和 low_limit_id 之间，因此还需要再判断 30 是否处于 trx_ids 数组内。由于事务 A 的 trx_ids=[20,30]，因此在数组内，这表示 id=2 的这条数据是与事务 A 在同一时刻启动的其他事务提交的，所以这条数据不能让事务 A 看到。
>
> 3）同理，id=3 的这条数据，trx_id 也为 30，因此也不能被事务 A 看见。
>
> ![image-20251201205638054](https://raw.githubusercontent.com/chen-1110/image/main/image-20251201205638054.png)
>
> 结论：最终事务 A 的第二次查询，只能查询出 id=1 的这条数据。这和事务 A 的第一次查询的结果是一样的，因此没有出现幻读现象，所以说在 MySQL 的可重复读隔离级别下，不存在幻读问题。

